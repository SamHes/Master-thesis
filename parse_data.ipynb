{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import requests\n",
    "import json\n",
    "import re\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = pd.read_csv('data/addresses/aave_addresses.csv')\n",
    "\n",
    "temp1 = pd.read_csv('data/exchanges/temp1.csv')\n",
    "temp2 = pd.read_csv('data/exchanges/temp2.csv')\n",
    "\n",
    "CEX_addresses = pd.read_csv('data/exchanges/cex.csv')\n",
    "CEX = set(CEX_addresses['address'].str.lower())\n",
    "\n",
    "EOA = set(addresses.loc[addresses['type'] == False, 'address'])\n",
    "CA = set(addresses.loc[addresses['type'] == True, 'address'])\n",
    "\n",
    "temp1 = set(temp1['address'].str.lower())\n",
    "temp2 = set(temp2['address'].str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\AppData\\Local\\Temp\\ipykernel_18660\\1363869768.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_temp2['address'] = filtered_temp2['address'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "filtered_temp2 = temp2[~temp2['address'].str.lower().isin(CEX)]\n",
    "filtered_temp2['address'] = filtered_temp2['address'].str.lower()\n",
    "filtered_temp2[['address', 'Label']].to_csv('filtered_temp2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/exchanges/cex_evms_addresses.sql', 'r', encoding='utf-8') as f:\n",
    "    content = f.read()\n",
    "\n",
    "rows = re.findall(r'\\((0x[a-fA-F0-9]+),\\s*\\'([^\\']+)\\'', content)\n",
    "\n",
    "with open('data/exchanges/cex.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow(['address', 'cex_name'])\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = pd.read_csv('data/addresses/combined_addresses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_addresses = addresses[addresses['type'] == False]\n",
    "filtered_addresses[['address']].to_csv('data/addresses/EOA_addresses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_info = {}\n",
    "with open('data/exchanges/exchanges.csv', newline='', encoding='utf-8') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        address = row['address'].lower()\n",
    "        address_info[address] = {\n",
    "            'label1': row.get('label', '')\n",
    "        }\n",
    "\n",
    "with open('data/exchanges/exchanges2.csv', newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        address = row['address'].lower()\n",
    "        if address not in address_info:\n",
    "            address_info[address] = {}\n",
    "        address_info[address].update({\n",
    "            'type': row.get('type', ''),\n",
    "            'name': row.get('name', '')\n",
    "        })\n",
    "        \n",
    "with open('data/exchanges/exchanges3.csv', newline='') as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        address = row['address'].lower()\n",
    "        if address not in address_info:\n",
    "            address_info[address] = {}\n",
    "        address_info[address].update({\n",
    "            'label2': row.get('label', '')\n",
    "        })\n",
    "\n",
    "wallet_exchange_map = {}\n",
    "with open('data/exchanges/exchanges.js') as f:\n",
    "    content = f.read()\n",
    "\n",
    "matches = re.findall(r'(?:[\"\\']?)([a-zA-Z0-9_-]+)(?:[\"\\']?)\\s*:\\s*\\[\\s*([^\\]]+?)\\s*\\]', content, re.DOTALL)\n",
    "\n",
    "for exchange, addrs_raw in matches:\n",
    "    addresses = re.findall(r\"'(0x[a-fA-F0-9]+)'\", addrs_raw)\n",
    "    for addr in addresses:\n",
    "        wallet_exchange_map[addr.lower()] = exchange\n",
    "\n",
    "for address, exchange in wallet_exchange_map.items():\n",
    "    if address not in address_info:\n",
    "        address_info[address] = {}\n",
    "    address_info[address]['exchange'] = exchange\n",
    "    \n",
    "with open('data/exchanges/exchanges.json', encoding='utf-8') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "for address, exchange in json_data.items():\n",
    "    address = address.lower()\n",
    "    if address not in address_info:\n",
    "        address_info[address] = {}\n",
    "    address_info[address]['exchange'] = exchange\n",
    "\n",
    "with open('data/exchanges/all_exchanges.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    fieldnames = ['address', 'label1', 'label2', 'type', 'name', 'exchange']\n",
    "    writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    for address, data in address_info.items():\n",
    "        row = {\n",
    "            'address': address,\n",
    "            'label1': data.get('label1', ''),\n",
    "            'label2': data.get('label2', ''),\n",
    "            'type': data.get('type', ''),\n",
    "            'name': data.get('name', ''),\n",
    "            'exchange': data.get('exchange', '')\n",
    "        }\n",
    "        writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_decimals = {\n",
    "    'aArbWETH': 10**18,\n",
    "    'cArbWETH': 10**18,\n",
    "    'aArbUSDC': 10**6,\n",
    "    'cArbUSDC': 10**6,\n",
    "    'aArbUSDT': 10**6,\n",
    "    'cArbUSDT': 10**6,\n",
    "    'aArbAAVE': 10**18,\n",
    "    'ArbAAVE': 10**18,\n",
    "    'ArbCOMP': 10**18\n",
    "}\n",
    "\n",
    "comp_tokens = ['COMP', 'cCOMP', 'cWETHv3', 'cUSDTv3', 'cUSDCv3']\n",
    "aave_tokens = ['AAVE', 'stkAAVE', 'aEthWETH', 'aEthUSDT', 'aEthUSDC']\n",
    "opt_tokens = ['aOptWETH', 'aOptUSDC', 'aOptUSDT', 'OptAAVE', 'cOptWETH', 'cOptUSDC', 'cOptUSDT', 'OptCOMP']\n",
    "pol_tokens = ['aPolWETH', 'aPolUSDC', 'aPolUSDT', 'PolAAVE', 'cPolUSDT', 'PolCOMP']\n",
    "bas_tokens = ['aBasWETH', 'aBasUSDC', 'cBasWETH', 'cBasUSDC', 'BasCOMP']\n",
    "arb_tokens = ['aArbWETH', 'aArbUSDC', 'aArbUSDT', 'ArbAAVE', 'cArbWETH', 'cArbUSDC', 'cArbUSDT', 'ArbCOMP']\n",
    "\n",
    "def scale_transfer_value(token, market):\n",
    "    df = pd.read_csv(f'data/{market}/{token}.csv')\n",
    "    df['value'] = df['value'].astype(float) / token_decimals[token]\n",
    "    df.to_csv(f'data/{market}/{token}.csv', index=False)\n",
    "    \n",
    "for token in arb_tokens:\n",
    "    scale_transfer_value(token, 'arbitrum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for token in aave_tokens:\n",
    "    df = pd.read_csv(f'data/aave/{token}.csv')\n",
    "    df['token'] = token\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "for token in comp_tokens:\n",
    "    df = pd.read_csv(f'data/compound/{token}.csv')\n",
    "    df['token'] = token\n",
    "    \n",
    "    df_list.append(df)\n",
    "\n",
    "for token in opt_tokens:\n",
    "    df = pd.read_csv(f'data/optimism/{token}.csv')\n",
    "    df['token'] = token\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "for token in pol_tokens:\n",
    "    df = pd.read_csv(f'data/polygon/{token}.csv')\n",
    "    df['token'] = token\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "for token in bas_tokens:\n",
    "    df = pd.read_csv(f'data/base/{token}.csv')\n",
    "    df['token'] = token\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "for token in arb_tokens:\n",
    "    df = pd.read_csv(f'data/arbitrum/{token}.csv')\n",
    "    df['token'] = token\n",
    "    \n",
    "    df_list.append(df)\n",
    "    \n",
    "combined_df = pd.concat(df_list, ignore_index=True)\n",
    "combined_df.to_csv('data/complete/combined_transfers.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/proposals/compound_proposals.json', 'r', encoding=\"utf8\") as f:\n",
    "    proposals_data = json.load(f)\n",
    "    \n",
    "with open('data/proposals/compound_votes.json', 'r', encoding=\"utf8\") as f:\n",
    "    votes_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_proposals(proposals_data):\n",
    "    for proposal in proposals_data['data']['proposals']:\n",
    "        proposal['abstainWeightedVotes'] = str(int(proposal['abstainWeightedVotes']) / 10**18)\n",
    "        proposal['againstWeightedVotes'] = str(int(proposal['againstWeightedVotes']) / 10**18)\n",
    "        proposal['forWeightedVotes'] = str(int(proposal['forWeightedVotes']) / 10**18)\n",
    "        proposal['quorumVotes'] = str(int(proposal['quorumVotes']) / 10**18)\n",
    "        proposal['totalWeightedVotes'] = str(int(proposal['totalWeightedVotes']) / 10**18)\n",
    "    return proposals_data\n",
    "\n",
    "scaled_proposals = scale_proposals(proposals_data)\n",
    "\n",
    "with open('data/proposals/compound_scaled_proposals.json', 'w') as f:\n",
    "    json.dump(scaled_proposals, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_votes(votes_data):\n",
    "    for proposal in votes_data:\n",
    "        for vote in proposal['votes']:\n",
    "            vote['weight'] = str(int(vote['weight']) / 10**18)\n",
    "    return votes_data\n",
    "\n",
    "scaled_votes = scale_votes(votes_data)\n",
    "\n",
    "with open('data/proposals/compound_scaled_votes.json', 'w') as f:\n",
    "    json.dump(scaled_votes, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/proposals/aave/aave_v2_on_chain_proposals_1_year.json', 'r', encoding=\"utf8\") as f:\n",
    "    aave_v2_proposals = json.load(f)\n",
    "\n",
    "with open('data/proposals/aave/aave_v3_on_chain_proposals_1_year.json', 'r', encoding=\"utf8\") as f:\n",
    "    aave_v3_proposals = json.load(f)\n",
    "    \n",
    "with open('data/proposals/aave/aave_v2_on_chain_votes_1_year.json', 'r', encoding=\"utf8\") as f:\n",
    "    aave_v2_votes = json.load(f)\n",
    "\n",
    "with open('data/proposals/aave/aave_v3_on_chain_votes_1_year.json', 'r', encoding=\"utf8\") as f:\n",
    "    aave_v3_votes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proposal in aave_v2_proposals['data']['proposals']:\n",
    "    proposal['currentNoVote'] = str(int(proposal['currentNoVote']) / 10**18)\n",
    "    proposal['currentYesVote'] = str(int(proposal['currentYesVote']) / 10**18)\n",
    "    \n",
    "with open('data/proposals/aave/aave_v2_on_chain_proposals_1_year.json', 'w') as f:\n",
    "    json.dump(aave_v2_proposals, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for proposal in aave_v3_proposals['data']['proposals']:\n",
    "    transactions = proposal['transactions']\n",
    "    if transactions.get('executed'):\n",
    "        proposal['state'] = \"Executed\"\n",
    "    elif transactions.get('canceled'):\n",
    "        proposal['state'] = \"Canceled\"\n",
    "    elif transactions.get('failed'):\n",
    "        proposal['state'] = \"Failed\"\n",
    "    else:\n",
    "        proposal['state'] = \"Active\"\n",
    "        \n",
    "    votes = proposal.get('votes')\n",
    "    if votes:\n",
    "        votes['againstVotes'] = str(int(votes['againstVotes']) / 10**18)\n",
    "        votes['forVotes'] = str(int(votes['forVotes']) / 10**18)\n",
    "        \n",
    "    for voters in aave_v3_votes:\n",
    "        if voters['proposal_id'] == int(proposal['id']):\n",
    "            proposal['totalCurrentVoters'] = len(voters['votes'])\n",
    "    \n",
    "with open('data/proposals/aave/aave_v3_on_chain_proposals_1_year.json', 'w') as f:\n",
    "    json.dump(aave_v3_proposals, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for votes in aave_v2_votes:\n",
    "    for vote in votes['votes']:\n",
    "        vote['weight'] = str(int(vote['weight']) / 10**18)\n",
    "        \n",
    "with open('data/proposals/aave/aave_v2_on_chain_votes_1_year.json', 'w') as f:\n",
    "    json.dump(aave_v2_votes, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for votes in aave_v3_votes:\n",
    "    for vote in votes['votes']:\n",
    "        if vote.get('choice') == 0:\n",
    "            vote['choice'] = \"AGAINST\"\n",
    "        elif vote.get('choice') == 1:\n",
    "            vote['choice'] = \"FOR\"\n",
    "        \n",
    "        vote['weight'] = str(vote['weight'] / 10**18)\n",
    "        \n",
    "with open('data/proposals/aave/aave_v3_on_chain_votes_1_year.json', 'w') as f:\n",
    "    json.dump(aave_v3_votes, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/proposals/compound/compound_votes_1_year.json', 'r', encoding=\"utf8\") as f:\n",
    "    comp_votes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for votes in comp_votes:\n",
    "    for vote in votes['votes']:\n",
    "        vote['weight'] = str(int(vote['weight']) / 10**18)\n",
    "        \n",
    "with open('data/proposals/compound/compound_votes_1_year.json', 'w') as f:\n",
    "    json.dump(comp_votes, f, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
