{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import os\n",
    "from web3 import Web3\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "api_key = os.getenv('INFURA_API_KEY_3')\n",
    "\n",
    "# infura_mainnet_url = f'https://mainnet.infura.io/v3/{api_key}'\n",
    "infura_polygon_url = f'https://polygon-mainnet.infura.io/v3/{api_key}'\n",
    "# infura_arbitrum_url = f'https://arbitrum-mainnet.infura.io/v3/{api_key}'\n",
    "\n",
    "web3 = Web3(Web3.HTTPProvider(infura_polygon_url))\n",
    "\n",
    "def is_contract(address):\n",
    "    code = web3.eth.get_code(Web3.to_checksum_address(address))\n",
    "    return len(code) > 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv1 = pd.read_csv('../data/addresses/checked_addresses_1_year_1.csv')\n",
    "csv2 = pd.read_csv('../data/addresses/checked_addresses_1_year.csv')\n",
    "csv3 = pd.read_csv('../data/addresses/node_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all DataFrames into one with an additional column indicating the source DataFrame\n",
    "combined_df = pd.concat([\n",
    "    csv1.assign(source='csv1'),\n",
    "    csv2.assign(source='csv2'),\n",
    "    csv3.assign(source='csv3')\n",
    "])\n",
    "\n",
    "# Group by address and check if there are conflicting types\n",
    "conflicting_addresses = combined_df.groupby('address').filter(\n",
    "    lambda group: group['type'].nunique() > 1 and group['source'].nunique() >= 2\n",
    ")\n",
    "\n",
    "# Extract and print the unique conflicting addresses\n",
    "conflicting_address_list = conflicting_addresses['address'].unique()\n",
    "print(conflicting_address_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfers_df = pd.read_csv('../data/1_year/reduced_transfers_1_year.csv')\n",
    "\n",
    "main_tokens = ['AAVE', 'aEthWETH', 'COMP', 'cWETHv3']\n",
    "arb_tokens = ['ArbAAVE', 'aArbWETH', 'ArbCOMP', 'cArbWETH']\n",
    "pol_tokens = ['PolAAVE', 'aPolWETH', 'PolCOMP']\n",
    "\n",
    "main_df = transfers_df[\n",
    "    transfers_df['token'].isin(main_tokens) &\n",
    "    (transfers_df['from'].str.lower() != transfers_df['to'].str.lower()) &\n",
    "    (transfers_df['value'] != 0)\n",
    "]\n",
    "\n",
    "arb_df = transfers_df[\n",
    "    transfers_df['token'].isin(arb_tokens) &\n",
    "    (transfers_df['from'].str.lower() != transfers_df['to'].str.lower()) &\n",
    "    (transfers_df['value'] != 0)\n",
    "]\n",
    "\n",
    "pol_df = transfers_df[\n",
    "    transfers_df['token'].isin(pol_tokens) &\n",
    "    (transfers_df['from'].str.lower() != transfers_df['to'].str.lower()) &\n",
    "    (transfers_df['value'] != 0)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_addresses = set(main_df['from'].unique()).union(set(main_df['to'].unique()))\n",
    "arb_addresses = set(arb_df['from'].unique()).union(set(arb_df['to'].unique()))\n",
    "pol_addresses = set(pol_df['from'].unique()).union(set(pol_df['to'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_arb = pd.read_csv('../data/addresses/checked_arb_addresses.csv')\n",
    "csv_pol = pd.read_csv('../data/addresses/checked_pol_addresses.csv')\n",
    "csv_main = pd.read_csv('../data/addresses/checked_main_addresses.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the dataframes on the 'address' column\n",
    "merged_df = pd.merge(csv_arb, csv_pol, on='address', suffixes=('_arb', '_pol'), how='inner')\n",
    "merged_df = pd.merge(merged_df, csv_main, on='address', suffixes=('', '_main'))\n",
    "\n",
    "# Find rows where the 'type' field isn't the same across the dataframes\n",
    "conflicting_types = merged_df[\n",
    "    (merged_df['type_arb'] != merged_df['type_pol']) |\n",
    "    (merged_df['type_arb'] != merged_df['type']) |\n",
    "    (merged_df['type_pol'] != merged_df['type'])\n",
    "]\n",
    "\n",
    "# Print the conflicting elements\n",
    "print(conflicting_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_csv = pd.concat([csv_arb, csv_pol, csv_main])\n",
    "combined_csv = combined_csv.groupby('address', as_index=False).agg({'type': 'any'})\n",
    "combined_csv.to_csv('combined_addresses.csv', index=False)\n",
    "\n",
    "print(\"Combined CSV saved as 'combined_addresses.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pol_addresses = set(pd.concat([csv2['address']]))\n",
    "\n",
    "# main_not_in_csv = pd.DataFrame(\n",
    "#     [address for address in main_addresses if address not in all_csv_addresses],\n",
    "#     columns=['address']\n",
    "# )\n",
    "\n",
    "# arb_not_in_csv = pd.DataFrame(\n",
    "#     [address for address in arb_addresses if address not in all_csv_addresses],\n",
    "#     columns=['address']\n",
    "# )\n",
    "\n",
    "pol_not_in_csv = pd.DataFrame(\n",
    "    [address for address in pol_addresses if address not in all_pol_addresses],\n",
    "    columns=['address']\n",
    ")\n",
    "\n",
    "print(len(main_not_in_csv), len(main_addresses))\n",
    "print(len(arb_not_in_csv), len(arb_addresses))\n",
    "print(len(pol_not_in_csv), len(pol_addresses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pol_not_in_csv_slice = pol_not_in_csv.iloc[:10000]\n",
    "\n",
    "for i, row in pol_not_in_csv_slice.iterrows():\n",
    "    print(i)\n",
    "    address = row['address']\n",
    "    pol_not_in_csv_slice.at[i, 'type'] = is_contract(address)\n",
    "    time.sleep(1/25)\n",
    "\n",
    "pol_not_in_csv_slice.to_csv('../data/addresses/checked_pol_addresses.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all distinct addresses from 'from' and 'to' columns in filtered_df\n",
    "distinct_filtered_addresses = pd.DataFrame(\n",
    "    pd.concat([filtered_df['from'], filtered_df['to']]).unique(), \n",
    "    columns=['address']\n",
    ")\n",
    "\n",
    "# Check how many of these addresses are in csv1, csv2, and csv3\n",
    "in_csv1 = distinct_filtered_addresses['address'].isin(csv1['address']).sum()\n",
    "in_csv2 = distinct_filtered_addresses['address'].isin(csv2['address']).sum()\n",
    "in_csv3 = distinct_filtered_addresses['address'].isin(csv3['address']).sum()\n",
    "\n",
    "# Find addresses that are not in any of the csv files\n",
    "not_in_any_csv = distinct_filtered_addresses[\n",
    "    ~distinct_filtered_addresses['address'].isin(pd.concat([csv1['address'], csv2['address'], csv3['address']]))\n",
    "]\n",
    "\n",
    "# Print the results\n",
    "print(f\"Addresses in csv1: {in_csv1}\")\n",
    "print(f\"Addresses in csv2: {in_csv2}\")\n",
    "print(f\"Addresses in csv3: {in_csv3}\")\n",
    "print(f\"Addresses not in any csv: {len(not_in_any_csv)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_pol = pd.read_csv('../data/addresses/checked_pol_addresses.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
